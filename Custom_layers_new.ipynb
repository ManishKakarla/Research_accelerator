{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "history_visible": true,
      "authorship_tag": "ABX9TyPhmFrfxQYMiR3hjhOsg0IK",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manishkakarla/Research_accelerator/blob/master/Custom_layers_new.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "import math\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "vzQHQRA7Jv8f"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hysq-GoeMxFi",
        "outputId": "8ff5f266-ef1d-4275-cdd8-7927427b61bc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow/python/compat/v2_compat.py:107: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "non-resource variables are not supported in the long term\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gradients_impl import gradients\n",
        "class IPC(keras.Model):\n",
        "\n",
        "    def __init__(self, filters,k,alpha):\n",
        "        '''Initializes the class and sets up the internal variables'''\n",
        "        # YOUR CODE HERE\n",
        "\n",
        "        super(IPC,self).__init__()\n",
        "        print(\"starting the  Improve convolution block\")\n",
        "        #self.inputs=inputs\n",
        "        #self.input_shap=self.inputs.shape\n",
        "        self.filters=filters\n",
        "        self.filters1=int(self.filters*alpha)\n",
        "        self.filters2=int(self.filters*(1-alpha))\n",
        "        self.k=k\n",
        "        self.alpha=alpha\n",
        "        self.z_i=None\n",
        "        self.seed=None\n",
        "        self.activated_beta=None\n",
        "        self.input_shap=(8,8,512)\n",
        "    \n",
        "    def build(self,inputs):\n",
        "        '''Create the state of the layer (weights)'''\n",
        "        # a and b should be initialized with random normal, c (or the bias) with zeros.\n",
        "        # remember to set these as trainable.\n",
        "        # YOUR CODE HERE\n",
        "        self.pointwise1=tf.keras.layers.Conv2D(self.filters2,1,strides=1,use_bias=False)\n",
        "        \n",
        "        seed_init=tf.random_uniform_initializer(minval=-1, maxval=0)\n",
        "        seed_init_val=seed_init(shape=(1,1,self.input_shap[-1],1),dtype='float32')\n",
        "        #seed_init_val=\n",
        "        #initializer = RandomUniform(-1, 1)\n",
        "        #config = initializer.get_config()\n",
        "        #initializer = RandomUniform.from_config(config)\n",
        "        self.seed=tf.Variable(initial_value=seed_init_val,trainable=True)\n",
        "        self.seed=tf.placeholder_with_default(self.seed,[None]+[i for i in self.seed.shape[1:]])\n",
        "        #self.z_i=tf.math.multiply(self.seed,self.alpha)\n",
        "        self.z_i=self.seed*self.alpha\n",
        "        \n",
        "\n",
        "      #print(self.seed)\n",
        "        #print(self.alpha)\n",
        "        #self.Z_i=tf.math.multiply(self.seed,self.alpha)\n",
        "        #print(self.alpha)\n",
        "       # self.tanh=tf.math.tanh(self.beta)\n",
        "        \n",
        "        self.pointwise2=tf.keras.layers.Conv2D(self.filters1,1,strides=1,use_bias=False)\n",
        "        self.convbeta=tf.keras.layers.Conv2D(self.k,(1,self.filters1+1),strides=1,padding='valid',use_bias=False)\n",
        "        \n",
        "      \n",
        "   \n",
        "    def call(self,inputs):\n",
        "        '''Defines the computation from inputs to outputs'''\n",
        "        # YOUR CODE HERE\n",
        "        #x^2a + xb + c.\n",
        "        inpu_shape=inputs.shape\n",
        "        #print(self.z_i.shape)\n",
        "        with tf.GradientTape() as tape:\n",
        "          beta=self.convbeta(self.z_i)\n",
        "        #print(f'beta shs{beta.shape}')\n",
        "          self.activated_beta=tf.math.tanh(beta)\n",
        "        #gradients=tape.gradient(se)\n",
        "        pw1=self.pointwise1(inputs)\n",
        "        print(f\"pointwise1{pw1.shape}\")\n",
        "        shape1=pw1.shape\n",
        "        #pw1_reshape=tf.reshape(pw1,(1,shape1[1],shape1[2],shape1[3]))\n",
        "        #pw1=tf.placeholder_with_default(pw1,[None]+[i for i in pw1_reshape.shape[1:]])\n",
        "        pw2=self.pointwise2(self.activated_beta)\n",
        "        print(\"after applying ptwise\",pw2.shape)\n",
        "        shape=pw2.shape\n",
        "        pw2_reshape=tf.reshape(pw2,(-1,inpu_shape[1],inpu_shape[2]\n",
        "                                    ,(shape[1]*shape[2]*shape[3])//(inpu_shape[1]*inpu_shape[2])))\n",
        "        \n",
        "        print(\"after reshaping\",pw2_reshape.shape)\n",
        "        \n",
        "        #pw= tf.placeholder_with_default(pw2, [None]+[i for i in [inpu_shape[1],inpu_shape[2]\n",
        "           #                         ,(shape[1]*shape[2]*shape[3])//(inpu_shape[1]*inpu_shape[2])]])\n",
        "       # print(f\"pointwiseshape2{pw.shape}\")\n",
        "       \n",
        "        return tf.keras.layers.Concatenate(axis=3)([pw1, pw2_reshape])\n",
        "\n",
        "\n",
        "    def train_step(self, inputs,targets):\n",
        "        #inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.compiled_loss(targets, predictions)               \n",
        "        gradients = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
        "        self.compiled_metrics.update_state(targets, predictions) \n",
        "        #print(m)\n",
        "        return {m.name: m.result() for m in self.metrics}        "
      ],
      "metadata": {
        "id": "C6wGVNTl2zUl"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=tf.keras.layers.Input((8,8,512) )\n",
        "x1 = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(input)\n",
        "print(x1)\n",
        "a=IPC(filters=512,alpha=0.875,k=9)\n",
        "outputs=a(x1)\n",
        "#a.train_step(x1,outputs)\n",
        "#print(f'output{a(x1).shape}')\n",
        "model= tf.keras.models.Model(input, outputs=a(x1))"
      ],
      "metadata": {
        "id": "nw9YHZbs6TzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86fde646-5090-4399-ea55-087db64e17f4"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"depthwise_conv2d_41/depthwise:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomModel(keras.Model):\n",
        "    def train_step(self, data):\n",
        "        inputs, targets = data\n",
        "        with tf.GradientTape() as tape:\n",
        "            predictions = self(inputs, training=True)\n",
        "            loss = self.compiled_loss(targets, predictions)               \n",
        "        gradients = tape.gradient(loss, self.trainable_weights)\n",
        "        self.optimizer.apply_gradients(zip(gradients, self.trainable_weights))\n",
        "        self.compiled_metrics.update_state(targets, predictions)          \n",
        "        return {m.name: m.result() for m in self.metrics}        "
      ],
      "metadata": {
        "id": "tfJplN1qAroz"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=tf.keras.layers.Input((8,8,512) )\n",
        "x1 = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(input)\n",
        "print(x1)\n",
        "a=IPC(filters=512,alpha=0.875,k=9)\n",
        "outputs=IPC(filters=512,alpha=0.875,k=9)(x1)\n",
        "\n",
        "model=CustomModel(input,outputs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eT7XLFGsAyWB",
        "outputId": "922068ab-d9a5-403b-a78c-cc05a97fd864"
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"depthwise_conv2d_42/depthwise:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
            "starting the  Improve convolution block\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "htDAg6Dt6nMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d080708b-67c0-498f-edda-eda271d8085a"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"custom_model_3\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_17 (InputLayer)       [(None, 8, 8, 512)]       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_42 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " ipc_30 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,449\n",
            "Trainable params: 45,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mobilenet_block(x, f, s=1):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(3, strides=s, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(f, 1, strides=1, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x =tf.keras.layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_mX3xI5iw9JG"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ManishNet(input_shape, n_classes):\n",
        "  \"\"\"\n",
        "  Manish's variation of MobileNetV1\n",
        "  \"\"\"\n",
        "  input = tf.keras.layers.Input(input_shape)\n",
        "  x = tf.keras.layers.Conv2D(32, 3, strides=1, padding='same')(input)\n",
        "  #print(\"conv2d --1\",x.shape)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  #print(\"batchNormalzation\",x.shape)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #print(\"activation\",x.shape)\n",
        "  x = mobilenet_block(x, 64)\n",
        "  x = mobilenet_block(x, 64,2)\n",
        "  #print(\"1st mobilenetblock_1\",x.shape)\n",
        "  x = mobilenet_block(x, 128, 1)\n",
        "  #print(\"2nd mobilenetblock_2\",x.shape)\n",
        "  x = mobilenet_block(x, 128)\n",
        "  #print(\"3rd mobilenetblock_3\",x.shape)\n",
        "\n",
        "  x = mobilenet_block(x, 256)\n",
        "  #print(\"4th mobilenetblock_4\",x.shape)\n",
        "  x = mobilenet_block(x, 256,2)\n",
        "  #print(\"5th mobilenet_block_5\",x.shape)\n",
        "\n",
        "  x = mobilenet_block(x, 512, 1)\n",
        "  \n",
        "  #print(\"6th mobilenetblock_6\",x.shape)\n",
        "  for i in range(5):\n",
        "    \n",
        "    x = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(x)\n",
        "    a = IPC(512,alpha=0.875,k=9)\n",
        "    x=a(x)\n",
        "   # print(\"jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\",x.shape)\n",
        "    #print(f\"{i+7} Improvedblock shape {x.shape}\")\n",
        "    \n",
        "  \n",
        "  x = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(x)\n",
        "  a = IPC(512,alpha=0.875,k=9)(x)\n",
        " # x=a(x)\n",
        "  #print(\"12 IPC\",x.shape)\n",
        "\n",
        "  x = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(x)\n",
        "  a = IPC(512,alpha=0.875,k=9)(x)\n",
        "  #x=a(x)\n",
        "  print(\"13 IPC\",x.shape)\n",
        "  \n",
        "  x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
        "  # x = tf.keras.layers.AveragePooling2D()(x)\n",
        "  \n",
        "  output = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "  print(output.shape)\n",
        "  \n",
        "  model = tf.keras.models.Model(input, output)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "0QoT9bgM-eHL"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=32,32,3\n",
        "n_classes=10\n",
        "model=ManishNet(input_shape, n_classes)"
      ],
      "metadata": {
        "id": "f4hmBQ6OyIvV",
        "outputId": "3984b1e5-f463-4301-ab36-364759de83ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "starting the  Improve convolution block\n",
            "pointwise1(?, 8, 8, 64)\n",
            "after applying ptwise (?, 1, 64, 448)\n",
            "after reshaping (?, 8, 8, 448)\n",
            "13 IPC (?, 8, 8, 512)\n",
            "(?, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AaFVGFlQxzwK"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "U1aB_4qWyPWa",
        "outputId": "dd0d9c50-e589-4826-8074-3f5cc8f2b015",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_18 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_103 (Conv2D)         (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_30 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_30 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_43 (Depthw  (None, 32, 32, 32)       320       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_31 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_31 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_104 (Conv2D)         (None, 32, 32, 64)        2112      \n",
            "                                                                 \n",
            " batch_normalization_32 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_32 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_44 (Depthw  (None, 16, 16, 64)       640       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_33 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_33 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_105 (Conv2D)         (None, 16, 16, 64)        4160      \n",
            "                                                                 \n",
            " batch_normalization_34 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_34 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_45 (Depthw  (None, 16, 16, 64)       640       \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_35 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_35 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_106 (Conv2D)         (None, 16, 16, 128)       8320      \n",
            "                                                                 \n",
            " batch_normalization_36 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_36 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_46 (Depthw  (None, 16, 16, 128)      1280      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_37 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_37 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_107 (Conv2D)         (None, 16, 16, 128)       16512     \n",
            "                                                                 \n",
            " batch_normalization_38 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_38 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_47 (Depthw  (None, 16, 16, 128)      1280      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_39 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_39 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_108 (Conv2D)         (None, 16, 16, 256)       33024     \n",
            "                                                                 \n",
            " batch_normalization_40 (Bat  (None, 16, 16, 256)      1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_40 (Activation)  (None, 16, 16, 256)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_48 (Depthw  (None, 8, 8, 256)        2560      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_41 (Bat  (None, 8, 8, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_41 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_109 (Conv2D)         (None, 8, 8, 256)         65792     \n",
            "                                                                 \n",
            " batch_normalization_42 (Bat  (None, 8, 8, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_42 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_49 (Depthw  (None, 8, 8, 256)        2560      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " batch_normalization_43 (Bat  (None, 8, 8, 256)        1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_43 (Activation)  (None, 8, 8, 256)         0         \n",
            "                                                                 \n",
            " conv2d_110 (Conv2D)         (None, 8, 8, 512)         131584    \n",
            "                                                                 \n",
            " batch_normalization_44 (Bat  (None, 8, 8, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_44 (Activation)  (None, 8, 8, 512)         0         \n",
            "                                                                 \n",
            " depthwise_conv2d_50 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " ipc_31 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_51 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " ipc_32 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_52 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " ipc_33 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_53 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " ipc_34 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_54 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " ipc_35 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_55 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " depthwise_conv2d_56 (Depthw  (None, 8, 8, 512)        4608      \n",
            " iseConv2D)                                                      \n",
            "                                                                 \n",
            " global_average_pooling2d_2   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 522,743\n",
            "Trainable params: 518,007\n",
            "Non-trainable params: 4,736\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ypnk5lbEyRia"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/54524124/dimension-mismatch-in-keras-during-model-fit"
      ],
      "metadata": {
        "id": "wkTVtb4yvqjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
      ],
      "metadata": {
        "id": "M36GE4wFy0WU"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.astype('float32')\n",
        "x_train/=255\n",
        "x_test=x_test.astype('float32')\n",
        "x_test/=255\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "1fLxcE8uZlZ7",
        "outputId": "65f9cc33-9baa-41e6-cc8b-9a6099ab4ccf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam( learning_rate=0.001 ) , metrics=[ 'acc' ] )"
      ],
      "metadata": {
        "id": "jr6PdJFMy7oZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "l4nBvcx8up_x"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DO1FAUK7vnmO"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,shuffle=True,batch_size=32)"
      ],
      "metadata": {
        "id": "_SfZBitWzEmo",
        "outputId": "6b896475-a235-43cc-8b09-19b6d47f4053",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 50000 samples\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-57-9ac5f395d0a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4275\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4276\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4277\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4278\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: ConcatOp : Dimension 0 in both shapes must be equal: shape[0] = [32,8,8,64] vs. shape[1] = [1,8,8,448]\n\t [[{{node ipc_31/concatenate_30/concat}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "issue for the gradients after concatenation\n",
        "https://github.com/tensorflow/tensorflow/issues/37726\n",
        "\n",
        "\n",
        "* https://www.google.com/search?q=how+to+calculte+gradients+for+concatenate+in+tf&rlz=1C1GCEB_enUS937US937&oq=how+to+calculte+gradients+for+concatenate+in+tf&aqs=chrome..69i57j33i10i160l2.22259j0j7&sourceid=chrome&ie=UTF-8"
      ],
      "metadata": {
        "id": "TtXUgnHF7wTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import math\n",
        "batch_size=32\n",
        "epochs=1\n",
        "\n",
        "class Generator(Sequence):\n",
        "    # Class is a dataset wrapper for better training performance\n",
        "    def __init__(self, x_set, y_set, batch_size=256):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = np.arange(self.x.shape[0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.floor(self.x.shape[0] / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = self.x[inds]\n",
        "        batch_y = self.y[inds]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "train_datagen = Generator(x_train, x_train, batch_size)\n",
        "test_datagen = Generator(x_test, x_test, batch_size)\n",
        "\n",
        "model.fit_generator(train_datagen,\n",
        "    steps_per_epoch=len(x_train)//batch_size,\n",
        "    validation_data=test_datagen,\n",
        "    validation_steps=len(x_test)//batch_size)"
      ],
      "metadata": {
        "id": "HAyQsbnhzF6J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}