{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Custom_layers.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "history_visible": true,
      "authorship_tag": "ABX9TyMpOjMpMyGC7/rD50NFMr5G",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/manishkakarla/Research_accelerator/blob/master/Custom_layers.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.python.keras.utils.vis_utils import plot_model\n",
        "import math\n",
        "from tensorflow.keras.layers import Layer\n",
        "from tensorflow import keras"
      ],
      "metadata": {
        "id": "vzQHQRA7Jv8f"
      },
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow.compat.v1 as tf\n",
        "tf.disable_v2_behavior()\n"
      ],
      "metadata": {
        "id": "hysq-GoeMxFi"
      },
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.python.ops.gradients_impl import gradients\n",
        "class IPC(keras.Model):\n",
        "\n",
        "    def __init__(self, filters,k,alpha):\n",
        "        '''Initializes the class and sets up the internal variables'''\n",
        "        # YOUR CODE HERE\n",
        "        super(IPC,self).__init__()\n",
        "        #self.inputs=inputs\n",
        "        #self.input_shap=self.inputs.shape\n",
        "        self.filters=filters\n",
        "        self.filters1=int(self.filters*alpha)\n",
        "        self.filters2=int(self.filters*(1-alpha))\n",
        "        self.k=k\n",
        "        self.alpha=alpha\n",
        "        self.z_i=None\n",
        "        self.seed=None\n",
        "        self.activated_beta=None\n",
        "        self.input_shap=(8,8,512)\n",
        "    \n",
        "    def build(self,inputs):\n",
        "        '''Create the state of the layer (weights)'''\n",
        "        # a and b should be initialized with random normal, c (or the bias) with zeros.\n",
        "        # remember to set these as trainable.\n",
        "        # YOUR CODE HERE\n",
        "        self.pointwise1=tf.keras.layers.Conv2D(self.filters2,1,strides=1,use_bias=False)\n",
        "        \n",
        "        seed_init=tf.random_uniform_initializer(minval=-1, maxval=0)\n",
        "        seed_init_val=seed_init(shape=(1,1,self.input_shap[-1],1),dtype='float32')\n",
        "        #seed_init_val=\n",
        "        #initializer = RandomUniform(-1, 1)\n",
        "        #config = initializer.get_config()\n",
        "        #initializer = RandomUniform.from_config(config)\n",
        "        self.seed=tf.Variable(initial_value=seed_init_val,trainable=True)\n",
        "        self.seed=tf.placeholder_with_default(self.seed,[None]+[i for i in self.seed.shape[1:]])\n",
        "        #self.z_i=tf.math.multiply(self.seed,self.alpha)\n",
        "        self.z_i=self.seed*self.alpha\n",
        "        \n",
        "\n",
        "      #print(self.seed)\n",
        "        #print(self.alpha)\n",
        "        #self.Z_i=tf.math.multiply(self.seed,self.alpha)\n",
        "        #print(self.alpha)\n",
        "       # self.tanh=tf.math.tanh(self.beta)\n",
        "        \n",
        "        self.pointwise2=tf.keras.layers.Conv2D(self.filters1,1,strides=1,use_bias=False)\n",
        "        self.convbeta=tf.keras.layers.Conv2D(self.k,(1,self.filters1+1),strides=1,padding='valid',use_bias=False)\n",
        "        \n",
        "      \n",
        "   \n",
        "    def call(self,inputs):\n",
        "        '''Defines the computation from inputs to outputs'''\n",
        "        # YOUR CODE HERE\n",
        "        #x^2a + xb + c.\n",
        "        inpu_shape=inputs.shape\n",
        "        #print(self.z_i.shape)\n",
        "        with tf.GradientTape() as tape:\n",
        "          beta=self.convbeta(self.z_i)\n",
        "        #print(f'beta shs{beta.shape}')\n",
        "          self.activated_beta=tf.math.tanh(beta)\n",
        "        #gradients=tape.gradient(se)\n",
        "        pw1=self.pointwise1(inputs)\n",
        "        print(f\"pointwise1{pw1.shape}\")\n",
        "        shape1=pw1.shape\n",
        "        pw1_reshape=tf.reshape(pw1,(1,shape1[1],shape1[2],shape1[3]))\n",
        "        pw1=tf.placeholder_with_default(pw1,[None]+[i for i in pw1_reshape.shape[1:]])\n",
        "        pw2=self.pointwise2(self.activated_beta)\n",
        "       # \n",
        "        shape=pw2.shape\n",
        "        pw2_reshape=tf.reshape(pw2,(1,inpu_shape[1],inpu_shape[2]\n",
        "                                    ,(shape[1]*shape[2]*shape[3])//(inpu_shape[1]*inpu_shape[2])))\n",
        "        \n",
        "        pw= tf.placeholder_with_default(pw2_reshape, [None]+[i for i in pw2_reshape.shape[1:]])\n",
        "        print(f\"pointwiseshape2{pw.shape}\")\n",
        "       \n",
        "        return tf.keras.layers.Concatenate(axis=3)([pw1, pw])"
      ],
      "metadata": {
        "id": "C6wGVNTl2zUl"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input=tf.keras.layers.Input((8,8,512) )\n",
        "x1 = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(input)\n",
        "print(x1)\n",
        "a=IPC(filters=512,alpha=0.875,k=9)\n",
        "#print(f'output{a(x1).shape}')\n",
        "model= tf.keras.models.Model(input, outputs=a(x1))"
      ],
      "metadata": {
        "id": "nw9YHZbs6TzQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d6d41a2-b1a7-4df0-c8ac-abf4a04f7f07"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tensor(\"depthwise_conv2d_100/depthwise:0\", shape=(?, 8, 8, 512), dtype=float32)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "htDAg6Dt6nMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b297cdf-90ac-4536-8e9c-50438dd866e9"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_23 (InputLayer)       [(None, 8, 8, 512)]       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_100 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " ipc_58 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 45,449\n",
            "Trainable params: 45,449\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def mobilenet_block(x, f, s=1):\n",
        "    x = tf.keras.layers.DepthwiseConv2D(3, strides=s, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x = tf.keras.layers.Activation('relu')(x)\n",
        "    \n",
        "    x = tf.keras.layers.Conv2D(f, 1, strides=1, padding='same')(x)\n",
        "    x = tf.keras.layers.BatchNormalization()(x)\n",
        "    x =tf.keras.layers.Activation('relu')(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "_mX3xI5iw9JG"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def ManishNet(input_shape, n_classes):\n",
        "  \"\"\"\n",
        "  Manish's variation of MobileNetV1\n",
        "  \"\"\"\n",
        "  input = tf.keras.layers.Input(input_shape)\n",
        "  x = tf.keras.layers.Conv2D(32, 3, strides=1, padding='same')(input)\n",
        "  #print(\"conv2d --1\",x.shape)\n",
        "  x = tf.keras.layers.BatchNormalization()(x)\n",
        "  #print(\"batchNormalzation\",x.shape)\n",
        "  x = tf.keras.layers.Activation('relu')(x)\n",
        "  #print(\"activation\",x.shape)\n",
        "  x = mobilenet_block(x, 64)\n",
        "  x = mobilenet_block(x, 64,2)\n",
        "  #print(\"1st mobilenetblock_1\",x.shape)\n",
        "  x = mobilenet_block(x, 128, 1)\n",
        "  #print(\"2nd mobilenetblock_2\",x.shape)\n",
        "  x = mobilenet_block(x, 128)\n",
        "  #print(\"3rd mobilenetblock_3\",x.shape)\n",
        "\n",
        "  x = mobilenet_block(x, 256)\n",
        "  #print(\"4th mobilenetblock_4\",x.shape)\n",
        "  x = mobilenet_block(x, 256,2)\n",
        "  #print(\"5th mobilenet_block_5\",x.shape)\n",
        "\n",
        "  x = mobilenet_block(x, 512, 1)\n",
        "  \n",
        "  #print(\"6th mobilenetblock_6\",x.shape)\n",
        "  for i in range(5):\n",
        "    \n",
        "    x = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(x)\n",
        "    a = IPC(512,alpha=0.875,k=9)\n",
        "    x=a(x)\n",
        "   # print(\"jjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjjj\",x.shape)\n",
        "    #print(f\"{i+7} Improvedblock shape {x.shape}\")\n",
        "    \n",
        "  \n",
        "  x = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(x)\n",
        "  a = IPC(512,alpha=0.875,k=9)(x)\n",
        " # x=a(x)\n",
        "  #print(\"12 IPC\",x.shape)\n",
        "\n",
        "  x = tf.keras.layers.DepthwiseConv2D(3, strides=1, padding='same',use_bias=False)(x)\n",
        "  a = IPC(512,alpha=0.875,k=9)(x)\n",
        "  #x=a(x)\n",
        "  print(\"13 IPC\",x.shape)\n",
        "  \n",
        "  x = tf.keras.layers.GlobalAvgPool2D()(x)\n",
        "  # x = tf.keras.layers.AveragePooling2D()(x)\n",
        "  \n",
        "  output = tf.keras.layers.Dense(n_classes, activation='softmax')(x)\n",
        "  print(output.shape)\n",
        "  \n",
        "  model = tf.keras.models.Model(input, output)\n",
        "  return model\n"
      ],
      "metadata": {
        "id": "0QoT9bgM-eHL"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_shape=32,32,3\n",
        "n_classes=10\n",
        "model=ManishNet(input_shape, n_classes)"
      ],
      "metadata": {
        "id": "f4hmBQ6OyIvV",
        "outputId": "bf3097a6-25be-4d10-e75f-d4243877e548",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n",
            "pointwise1(?, 8, 8, 64)\n",
            "pointwiseshape2(?, 8, 8, 448)\n",
            "13 IPC (?, 8, 8, 512)\n",
            "(?, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "AaFVGFlQxzwK"
      },
      "execution_count": 116,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "U1aB_4qWyPWa",
        "outputId": "675daf51-bcc4-4a5e-a849-40f931b05f10",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_24 (InputLayer)       [(None, 32, 32, 3)]       0         \n",
            "                                                                 \n",
            " conv2d_211 (Conv2D)         (None, 32, 32, 32)        896       \n",
            "                                                                 \n",
            " batch_normalization_90 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_90 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_101 (Depth  (None, 32, 32, 32)       320       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_91 (Bat  (None, 32, 32, 32)       128       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_91 (Activation)  (None, 32, 32, 32)        0         \n",
            "                                                                 \n",
            " conv2d_212 (Conv2D)         (None, 32, 32, 64)        2112      \n",
            "                                                                 \n",
            " batch_normalization_92 (Bat  (None, 32, 32, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_92 (Activation)  (None, 32, 32, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_102 (Depth  (None, 16, 16, 64)       640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_93 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_93 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_213 (Conv2D)         (None, 16, 16, 64)        4160      \n",
            "                                                                 \n",
            " batch_normalization_94 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_94 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_103 (Depth  (None, 16, 16, 64)       640       \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_95 (Bat  (None, 16, 16, 64)       256       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_95 (Activation)  (None, 16, 16, 64)        0         \n",
            "                                                                 \n",
            " conv2d_214 (Conv2D)         (None, 16, 16, 128)       8320      \n",
            "                                                                 \n",
            " batch_normalization_96 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_96 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_104 (Depth  (None, 16, 16, 128)      1280      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_97 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_97 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_215 (Conv2D)         (None, 16, 16, 128)       16512     \n",
            "                                                                 \n",
            " batch_normalization_98 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_98 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " depthwise_conv2d_105 (Depth  (None, 16, 16, 128)      1280      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_99 (Bat  (None, 16, 16, 128)      512       \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " activation_99 (Activation)  (None, 16, 16, 128)       0         \n",
            "                                                                 \n",
            " conv2d_216 (Conv2D)         (None, 16, 16, 256)       33024     \n",
            "                                                                 \n",
            " batch_normalization_100 (Ba  (None, 16, 16, 256)      1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_100 (Activation)  (None, 16, 16, 256)      0         \n",
            "                                                                 \n",
            " depthwise_conv2d_106 (Depth  (None, 8, 8, 256)        2560      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_101 (Ba  (None, 8, 8, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_101 (Activation)  (None, 8, 8, 256)        0         \n",
            "                                                                 \n",
            " conv2d_217 (Conv2D)         (None, 8, 8, 256)         65792     \n",
            "                                                                 \n",
            " batch_normalization_102 (Ba  (None, 8, 8, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_102 (Activation)  (None, 8, 8, 256)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_107 (Depth  (None, 8, 8, 256)        2560      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " batch_normalization_103 (Ba  (None, 8, 8, 256)        1024      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_103 (Activation)  (None, 8, 8, 256)        0         \n",
            "                                                                 \n",
            " conv2d_218 (Conv2D)         (None, 8, 8, 512)         131584    \n",
            "                                                                 \n",
            " batch_normalization_104 (Ba  (None, 8, 8, 512)        2048      \n",
            " tchNormalization)                                               \n",
            "                                                                 \n",
            " activation_104 (Activation)  (None, 8, 8, 512)        0         \n",
            "                                                                 \n",
            " depthwise_conv2d_108 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " ipc_59 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_109 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " ipc_60 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_110 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " ipc_61 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_111 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " ipc_62 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_112 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " ipc_63 (IPC)                (None, 8, 8, 512)         40841     \n",
            "                                                                 \n",
            " depthwise_conv2d_113 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " depthwise_conv2d_114 (Depth  (None, 8, 8, 512)        4608      \n",
            " wiseConv2D)                                                     \n",
            "                                                                 \n",
            " global_average_pooling2d_6   (None, 512)              0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " dense_6 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 522,743\n",
            "Trainable params: 518,007\n",
            "Non-trainable params: 4,736\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Ypnk5lbEyRia"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://stackoverflow.com/questions/54524124/dimension-mismatch-in-keras-during-model-fit"
      ],
      "metadata": {
        "id": "wkTVtb4yvqjr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n"
      ],
      "metadata": {
        "id": "M36GE4wFy0WU"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x_train=x_train.astype('float32')\n",
        "x_train/=255\n",
        "x_test=x_test.astype('float32')\n",
        "x_test/=255\n",
        "print(x_train.shape)"
      ],
      "metadata": {
        "id": "1fLxcE8uZlZ7",
        "outputId": "bed6fc9c-ca1c-4d35-c435-1d7358c21abf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(50000, 32, 32, 3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile( loss='sparse_categorical_crossentropy', optimizer=tf.keras.optimizers.Adam( learning_rate=0.001 ) , metrics=[ 'acc' ] )"
      ],
      "metadata": {
        "id": "jr6PdJFMy7oZ"
      },
      "execution_count": 120,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.utils import Sequence\n",
        "import math\n",
        "batch_size=32\n",
        "epochs=1\n",
        "\n",
        "class Generator(Sequence):\n",
        "    # Class is a dataset wrapper for better training performance\n",
        "    def __init__(self, x_set, y_set, batch_size=256):\n",
        "        self.x, self.y = x_set, y_set\n",
        "        self.batch_size = batch_size\n",
        "        self.indices = np.arange(self.x.shape[0])\n",
        "\n",
        "    def __len__(self):\n",
        "        return math.floor(self.x.shape[0] / self.batch_size)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        inds = self.indices[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        batch_x = self.x[inds]\n",
        "        batch_y = self.y[inds]\n",
        "        return batch_x, batch_y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        np.random.shuffle(self.indices)\n",
        "\n",
        "train_datagen = Generator(x_train, x_train, batch_size)\n",
        "test_datagen = Generator(x_test, x_test, batch_size)\n",
        "\n",
        "model.fit_generator(train_datagen,\n",
        "    steps_per_epoch=len(x_train)//batch_size,\n",
        "    validation_data=test_datagen,\n",
        "    validation_steps=len(x_test)//batch_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 416
        },
        "id": "l4nBvcx8up_x",
        "outputId": "6a667393-920c-4c46-fdd5-ab67fa8ac03b"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:31: UserWarning: `model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-121-7eaa8f42b92c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtest_datagen\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     validation_steps=len(x_test)//batch_size)\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1245\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1246\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1247\u001b[0;31m         initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1249\u001b[0m   def evaluate_generator(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    584\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_generator_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m       \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[1;32m   1074\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_sample_weight_modes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1075\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1076\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1077\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1078\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4275\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4276\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4277\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4278\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: Can not squeeze dim[3], expected a dimension of 1, got 3\n\t [[{{node metrics_18/acc/Squeeze}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "DO1FAUK7vnmO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(x_train,y_train,shuffle=True,batch_size=32)"
      ],
      "metadata": {
        "id": "_SfZBitWzEmo",
        "outputId": "f3626204-538b-4a7b-bded-26eaec8b2b0a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        }
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train on 50000 samples\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidArgumentError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-122-9ac5f395d0a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    794\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    795\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 796\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    797\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    798\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    657\u001b[0m         \u001b[0mvalidation_freq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_freq\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 658\u001b[0;31m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    660\u001b[0m   def evaluate(self,\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/engine/training_arrays_v1.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[0;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, validation_freq, mode, validation_in_fit, prepared_feed_values_from_dataset, steps_name, **kwargs)\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m         \u001b[0;31m# Get outputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 377\u001b[0;31m         \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    378\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   4274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4275\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[0;32m-> 4276\u001b[0;31m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[1;32m   4277\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4278\u001b[0m     output_structure = tf.nest.pack_sequence_as(\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1480\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1481\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1482\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1483\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1484\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInvalidArgumentError\u001b[0m: All dimensions except 3 must match. Input 1 has shape [1 8 8 448] and doesn't match input 0 with shape [32 8 8 64].\n\t [[{{node training_11/Adam/gradients/gradients/ipc_59/concatenate_56/concat_grad/ConcatOffset}}]]"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "issue for the gradients after concatenation\n",
        "https://github.com/tensorflow/tensorflow/issues/37726\n",
        "\n",
        "\n",
        "* https://www.google.com/search?q=how+to+calculte+gradients+for+concatenate+in+tf&rlz=1C1GCEB_enUS937US937&oq=how+to+calculte+gradients+for+concatenate+in+tf&aqs=chrome..69i57j33i10i160l2.22259j0j7&sourceid=chrome&ie=UTF-8"
      ],
      "metadata": {
        "id": "TtXUgnHF7wTJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "HAyQsbnhzF6J"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}